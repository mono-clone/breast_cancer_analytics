{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcfaefbb-89db-48c9-8b91-141cf7014df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/breast_cancer_analytics/notebooks/functions.py:278: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y: pd.Series(),\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "# 基本的なライブラリ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "# 描画ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from seaborn_analyzer import CustomPairPlot\n",
    "import graphviz\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "from IPython.display import HTML\n",
    "from six import StringIO\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "# 前処理\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# 補完\n",
    "from sklearn.experimental import (\n",
    "    enable_iterative_imputer,\n",
    ")  # IterativeImputerをimportするために必要\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "\n",
    "# エンコード\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "# データセット分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 特徴量選択\n",
    "from sklearn.feature_selection import (\n",
    "    GenericUnivariateSelect,\n",
    "    f_classif,\n",
    "    mutual_info_classif,\n",
    "    chi2,\n",
    ")\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# 学習中\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import learning_curve, cross_validate, cross_val_score\n",
    "\n",
    "# 評価指標\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "# config python file\n",
    "import config\n",
    "\n",
    "SEED = config.SEED\n",
    "\n",
    "\n",
    "from functions import *\n",
    "\n",
    "fix_seed(SEED)\n",
    "\n",
    "\n",
    "# 最大表示列数の指定（ここでは50列を指定）N\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748b911-cac6-48d6-8c75-5d9cc365f904",
   "metadata": {},
   "source": [
    "# 目的\n",
    "遺伝子学的分類に基づいた、予後の2値分類を実施する。  \n",
    "分類はCLAUDIN_SUBTYPEに基づいて実施。  \n",
    "予後は5年、10年、15年の3つの年次に分けている。Trueで死亡であることに注意すること。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa0fd00-a463-480a-b10c-38fc01dbe647",
   "metadata": {
    "tags": []
   },
   "source": [
    "# データ読み込み\n",
    "読み込み元：\n",
    "    config.INTERIM_PICKLE_PREPROCESSED_PROGNOSIS_CROSS_DIR + \"/claudin_subtype_chi2\"\n",
    "\n",
    "サブタイプ毎のデータを使用\n",
    "\n",
    "データの種類が多いので、辞書型で表現する  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc7b860-1625-469c-b5f7-547c007ed87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ構造を辞書に反映するための関数\n",
    "def dir2dict(dic, path):\n",
    "    for k in os.listdir(path):\n",
    "        if os.path.isdir(os.path.join(path, k)):\n",
    "            if not k in dic:\n",
    "                dic[k] = dict()\n",
    "            dir2dict(dic[k], path + \"/\" + k)\n",
    "        else:\n",
    "            if k[0] == \"X\" or k[0] == \"y\":\n",
    "                dic[k.split(\".\")[0]] = pd.read_pickle(path + \"/\" + k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90da1a2b-df04-4387-ba48-39851d384b92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dict = dict()\n",
    "dir2dict(df_dict, config.INTERIM_PICKLE_PREPROCESSED_PROGNOSIS_CROSS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3011d730-a100-4755-97d0-a1fce8415500",
   "metadata": {},
   "source": [
    "# モデルのトレーニング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a02154-d9fb-4b12-b8f3-602baff4a8dc",
   "metadata": {},
   "source": [
    "## データ全体のベースライン・学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b67526-e97d-4f6d-8b56-1af1b01caea1",
   "metadata": {},
   "source": [
    "### boruta適用データのベースライン・基本学習結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d97bf9-2362-4127-9b4b-6cae35c9cbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "予後年数：05年:\n",
      "accuracyベースライン： ('0>1', 0.812)\n",
      "使用特徴量： Index(['BCL2', 'C1orf106', 'C6orf97', 'CDCA5', 'ESR1', 'EXO1', 'FAM83D',\n",
      "       'FGD3', 'FGFR4', 'HPN', 'IL6ST', 'KIF20A', 'KRT80', 'MAPT', 'PREX1',\n",
      "       'SERPINA3', 'SUSD3', 'TMEM26'],\n",
      "      dtype='object')\n",
      "学習サンプルサイズ： (1306, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ラベル比率：'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    1060\n",
       "1     246\n",
       "Name: OS_05years, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [12:16, 66.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.722308</td>\n",
       "      <td>0.721321</td>\n",
       "      <td>0.462233</td>\n",
       "      <td>0.457753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quadratic Discriminant Analysis</th>\n",
       "      <td>0.783733</td>\n",
       "      <td>0.739630</td>\n",
       "      <td>0.468855</td>\n",
       "      <td>0.343321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.857410</td>\n",
       "      <td>0.799389</td>\n",
       "      <td>0.501189</td>\n",
       "      <td>0.314517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.862344</td>\n",
       "      <td>0.777962</td>\n",
       "      <td>0.560306</td>\n",
       "      <td>0.298459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <td>0.841927</td>\n",
       "      <td>0.778667</td>\n",
       "      <td>0.439279</td>\n",
       "      <td>0.224470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial SVM</th>\n",
       "      <td>0.840564</td>\n",
       "      <td>0.805514</td>\n",
       "      <td>0.330344</td>\n",
       "      <td>0.162169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.816403</td>\n",
       "      <td>0.811615</td>\n",
       "      <td>0.171174</td>\n",
       "      <td>0.128121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.844309</td>\n",
       "      <td>0.810869</td>\n",
       "      <td>0.312603</td>\n",
       "      <td>0.118968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>0.811639</td>\n",
       "      <td>0.811650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM</th>\n",
       "      <td>0.811639</td>\n",
       "      <td>0.811650</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sigmoid SVM</th>\n",
       "      <td>0.811639</td>\n",
       "      <td>0.811650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 acc_train  acc_test  f1_train   f1_test\n",
       "classifier                                                              \n",
       "Naive Bayes                       0.722308  0.721321  0.462233  0.457753\n",
       "Quadratic Discriminant Analysis   0.783733  0.739630  0.468855  0.343321\n",
       "AdaBoost                          0.857410  0.799389  0.501189  0.314517\n",
       "Decision Tree                     0.862344  0.777962  0.560306  0.298459\n",
       "Nearest Neighbors                 0.841927  0.778667  0.439279  0.224470\n",
       "Polynomial SVM                    0.840564  0.805514  0.330344  0.162169\n",
       "Logistic Regression               0.816403  0.811615  0.171174  0.128121\n",
       "Random Forest                     0.844309  0.810869  0.312603  0.118968\n",
       "Linear SVM                        0.811639  0.811650  0.000000  0.000000\n",
       "RBF SVM                           0.811639  0.811650  0.000889  0.000000\n",
       "Sigmoid SVM                       0.811639  0.811650  0.000000  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "予後年数：10年:\n",
      "accuracyベースライン： ('0>1', 0.636)\n",
      "使用特徴量： Index(['ATHL1', 'AURKA', 'BCL2', 'CCNB2', 'CDC20', 'CDCA5', 'CLIC6', 'FAM83D',\n",
      "       'FGD3', 'FGFR4', 'GRB7', 'HIST1H4H', 'KIF20A', 'KRT80', 'LRP2', 'MAPT',\n",
      "       'NAT1', 'PGR', 'PTTG1', 'SERPINA1', 'SPATA18', 'STC2', 'SUSD3',\n",
      "       'TMEM26', 'TPX2', 'TROAP', 'UBE2C', 'UHRF1'],\n",
      "      dtype='object')\n",
      "学習サンプルサイズ： (1048, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ラベル比率：'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    667\n",
       "1    381\n",
       "Name: OS_10years, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [12:53, 70.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.650552</td>\n",
       "      <td>0.645027</td>\n",
       "      <td>0.572135</td>\n",
       "      <td>0.561634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quadratic Discriminant Analysis</th>\n",
       "      <td>0.743320</td>\n",
       "      <td>0.643150</td>\n",
       "      <td>0.647773</td>\n",
       "      <td>0.507165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.687447</td>\n",
       "      <td>0.674588</td>\n",
       "      <td>0.495516</td>\n",
       "      <td>0.472252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <td>0.755195</td>\n",
       "      <td>0.629771</td>\n",
       "      <td>0.636979</td>\n",
       "      <td>0.459579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM</th>\n",
       "      <td>0.730174</td>\n",
       "      <td>0.679313</td>\n",
       "      <td>0.547958</td>\n",
       "      <td>0.459249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial SVM</th>\n",
       "      <td>0.855386</td>\n",
       "      <td>0.617344</td>\n",
       "      <td>0.789309</td>\n",
       "      <td>0.445140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>0.689672</td>\n",
       "      <td>0.670778</td>\n",
       "      <td>0.479678</td>\n",
       "      <td>0.442197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.779153</td>\n",
       "      <td>0.627839</td>\n",
       "      <td>0.669802</td>\n",
       "      <td>0.437913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.831319</td>\n",
       "      <td>0.666941</td>\n",
       "      <td>0.729589</td>\n",
       "      <td>0.435684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.791242</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.692874</td>\n",
       "      <td>0.412793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sigmoid SVM</th>\n",
       "      <td>0.636451</td>\n",
       "      <td>0.636493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 acc_train  acc_test  f1_train   f1_test\n",
       "classifier                                                              \n",
       "Naive Bayes                       0.650552  0.645027  0.572135  0.561634\n",
       "Quadratic Discriminant Analysis   0.743320  0.643150  0.647773  0.507165\n",
       "Logistic Regression               0.687447  0.674588  0.495516  0.472252\n",
       "Nearest Neighbors                 0.755195  0.629771  0.636979  0.459579\n",
       "RBF SVM                           0.730174  0.679313  0.547958  0.459249\n",
       "Polynomial SVM                    0.855386  0.617344  0.789309  0.445140\n",
       "Linear SVM                        0.689672  0.670778  0.479678  0.442197\n",
       "AdaBoost                          0.779153  0.627839  0.669802  0.437913\n",
       "Random Forest                     0.831319  0.666941  0.729589  0.435684\n",
       "Decision Tree                     0.791242  0.601136  0.692874  0.412793\n",
       "Sigmoid SVM                       0.636451  0.636493  0.000000  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "予後年数：15年:\n",
      "accuracyベースライン： ('0>1', 0.533)\n",
      "使用特徴量： Index(['AURKA', 'CCL19', 'CIDEC', 'CLEC3A', 'CLIC6', 'CYP4F22', 'DARC', 'FGD3',\n",
      "       'HIST1H4H', 'LOC389033', 'MAPT', 'MFAP4', 'MYBPC1', 'NAT1', 'PLIN4',\n",
      "       'S100P', 'SERPINA3', 'SFRP1', 'SPP1', 'SUSD3', 'TAT', 'TMEM26', 'UBE2C',\n",
      "       'VTCN1'],\n",
      "      dtype='object')\n",
      "学習サンプルサイズ： (811, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ラベル比率：'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    432\n",
       "0    379\n",
       "Name: OS_15years, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [03:37, 19.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.807370</td>\n",
       "      <td>0.653538</td>\n",
       "      <td>0.829001</td>\n",
       "      <td>0.696584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sigmoid SVM</th>\n",
       "      <td>0.532677</td>\n",
       "      <td>0.532746</td>\n",
       "      <td>0.695061</td>\n",
       "      <td>0.692588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM</th>\n",
       "      <td>0.735717</td>\n",
       "      <td>0.638783</td>\n",
       "      <td>0.773667</td>\n",
       "      <td>0.690699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.674475</td>\n",
       "      <td>0.652288</td>\n",
       "      <td>0.708195</td>\n",
       "      <td>0.682886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.645980</td>\n",
       "      <td>0.641238</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.676557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>0.677215</td>\n",
       "      <td>0.632520</td>\n",
       "      <td>0.712804</td>\n",
       "      <td>0.668490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <td>0.752706</td>\n",
       "      <td>0.614107</td>\n",
       "      <td>0.781027</td>\n",
       "      <td>0.659791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.798192</td>\n",
       "      <td>0.625173</td>\n",
       "      <td>0.813878</td>\n",
       "      <td>0.657457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quadratic Discriminant Analysis</th>\n",
       "      <td>0.734622</td>\n",
       "      <td>0.611593</td>\n",
       "      <td>0.766278</td>\n",
       "      <td>0.654535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial SVM</th>\n",
       "      <td>0.843129</td>\n",
       "      <td>0.609124</td>\n",
       "      <td>0.856205</td>\n",
       "      <td>0.638766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.778052</td>\n",
       "      <td>0.604246</td>\n",
       "      <td>0.791002</td>\n",
       "      <td>0.609936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 acc_train  acc_test  f1_train   f1_test\n",
       "classifier                                                              \n",
       "Random Forest                     0.807370  0.653538  0.829001  0.696584\n",
       "Sigmoid SVM                       0.532677  0.532746  0.695061  0.692588\n",
       "RBF SVM                           0.735717  0.638783  0.773667  0.690699\n",
       "Logistic Regression               0.674475  0.652288  0.708195  0.682886\n",
       "Naive Bayes                       0.645980  0.641238  0.684000  0.676557\n",
       "Linear SVM                        0.677215  0.632520  0.712804  0.668490\n",
       "Nearest Neighbors                 0.752706  0.614107  0.781027  0.659791\n",
       "AdaBoost                          0.798192  0.625173  0.813878  0.657457\n",
       "Quadratic Discriminant Analysis   0.734622  0.611593  0.766278  0.654535\n",
       "Polynomial SVM                    0.843129  0.609124  0.856205  0.638766\n",
       "Decision Tree                     0.778052  0.604246  0.791002  0.609936"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for year in range(5, 16, 5):  # 予後年数毎のループ\n",
    "\n",
    "    X_train_tmp = df_dict[\"chi2\"][\"boruta\"][\"train\"][\"X{0:0=2}\".format(year)]\n",
    "    y_train_tmp = df_dict[\"chi2\"][\"boruta\"][\"train\"][\"y{0:0=2}\".format(year)]\n",
    "    X_test_tmp = df_dict[\"chi2\"][\"boruta\"][\"test\"][\"X{0:0=2}\".format(year)]\n",
    "    y_test_tmp = df_dict[\"chi2\"][\"boruta\"][\"test\"][\"y{0:0=2}\".format(year)]\n",
    "    assert X_train_tmp.shape[0] == y_train_tmp.shape[0], \"train size is incorrect\"\n",
    "    assert X_test_tmp.shape[0] == y_test_tmp.shape[0], \"test size is incorrect\"\n",
    "\n",
    "    # accuracyの表示\n",
    "    print(\"----------\" * 10)\n",
    "    print(\"予後年数：{0:0=2}年:\".format(year))\n",
    "    if accuracy_score(y_train_tmp, np.zeros(len(y_train_tmp))) >= 0.5:\n",
    "        score = (\n",
    "            \"0>1\".format(year),\n",
    "            round(accuracy_score(y_train_tmp, np.zeros(len(y_train_tmp))), 3),\n",
    "        )\n",
    "    else:\n",
    "        score = (\n",
    "            \"0>1\".format(year),\n",
    "            round(accuracy_score(y_train_tmp, np.ones(len(y_train_tmp))), 3),\n",
    "        )\n",
    "    print(\"accuracyベースライン：\", score)\n",
    "    print(\"使用特徴量：\", X_train_tmp.columns)\n",
    "    print(\"学習サンプルサイズ：\", X_train_tmp.shape)\n",
    "    display(\"ラベル比率：\", y_train_tmp.value_counts())\n",
    "    display(compare_bcms(X_train_tmp, y_train_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8886c98c-4362-4733-9056-09696cdc5b99",
   "metadata": {
    "tags": []
   },
   "source": [
    "## subtype毎のベースライン・学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8307d5b7-4c3e-4347-bf51-ce2c4a2e8cc0",
   "metadata": {},
   "source": [
    "### borutaを使用した場合のベースライン・基本学習結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57426c66-8523-4710-8ea6-8b922919f530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['claudin-low', 'LumA', 'LumB', 'Her2', 'Normal', 'Basal'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\n",
    "    config.INTERIM_PICKLE_PREPROCESSED_PROGNOSIS_CROSS_DIR + \"/df_cross.pkl\"\n",
    ")[\"CLAUDIN_SUBTYPE\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc1cb1f-56e7-455c-b379-f0d76162ff57",
   "metadata": {
    "tags": []
   },
   "source": [
    "for year in range(5, 16, 5):  # 予後年数毎のループ\n",
    "    print(\"====={0:0=2}\".format(year) * 10)\n",
    "\n",
    "    for subtype in pd.read_pickle(\n",
    "        config.INTERIM_PICKLE_PREPROCESSED_PROGNOSIS_CROSS_DIR + \"/df_cross.pkl\"\n",
    "    )[\"CLAUDIN_SUBTYPE\"].unique():\n",
    "        X_train_tmp = df_dict[\"chi2\"][\"claudin_subtype\"][\"train\"][\n",
    "            \"X{0:0=2}_{1}\".format(year, subtype)\n",
    "        ]\n",
    "        y_train_tmp = df_dict[\"chi2\"][\"claudin_subtype\"][\"train\"][\n",
    "            \"y{0:0=2}_{1}\".format(year, subtype)\n",
    "        ]\n",
    "        X_test_tmp = df_dict[\"chi2\"][\"claudin_subtype\"][\"test\"][\n",
    "            \"X{0:0=2}_{1}\".format(year, subtype)\n",
    "        ]\n",
    "        y_test_tmp = df_dict[\"chi2\"][\"claudin_subtype\"][\"test\"][\n",
    "            \"y{0:0=2}_{1}\".format(year, subtype)\n",
    "        ]\n",
    "        assert X_train_tmp.shape[0] == y_train_tmp.shape[0], \"train size is incorrect\"\n",
    "        assert X_test_tmp.shape[0] == y_test_tmp.shape[0], \"test size is incorrect\"\n",
    "\n",
    "        # accuracyの表示\n",
    "        print(\"----------\" * 10)\n",
    "        print(\"subtype: \", subtype)\n",
    "        print(\"予後年数：{0:0=2}年:\".format(year))\n",
    "        if accuracy_score(y_train_tmp, np.zeros(len(y_train_tmp))) >= 0.5:\n",
    "            score = (\n",
    "                \"0>1\".format(year),\n",
    "                round(accuracy_score(y_train_tmp, np.zeros(len(y_train_tmp))), 3),\n",
    "            )\n",
    "        else:\n",
    "            score = (\n",
    "                \"0>1\".format(year),\n",
    "                round(accuracy_score(y_train_tmp, np.ones(len(y_train_tmp))), 3),\n",
    "            )\n",
    "        print(\"accuracyベースライン：\", score)\n",
    "        print(\"使用特徴量：\", X_train_tmp.columns)\n",
    "        print(\"学習サンプルサイズ：\", X_train_tmp.shape)\n",
    "        display(\"ラベル比率：\", y_train_tmp.value_counts())\n",
    "        display(compare_bcms(X_train_tmp, y_train_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a10ef29-6dba-4063-a246-0168ef5b13df",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 予測・最適化\n",
    "\n",
    "分類器を学習させ、パラメータのチューニングを行い、高い予測精度を目指す。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d1d6e-1167-4dcc-a216-ecf4755caa74",
   "metadata": {},
   "source": [
    "## optuna\n",
    "\n",
    "モデルのパラメータをベイズ最適化に基づいて最適化していくoptunaを使用する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8430aab2-ace2-4ec6-8aa8-d07f0abb1545",
   "metadata": {},
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633dcd66-996f-461a-85de-cf544da6883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # ランダムフォレストのパラメータチューニング\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 10, 1000)\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 50, log=True)\n",
    "    max_leaf_noddes = trial.suggest_int(\"max_leaf_nodes\", 2, 100)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_noddes,\n",
    "        max_features=max_features,\n",
    "        random_state=SEED,\n",
    "    )\n",
    "    # 10分割交差検証によるテストデータのaccuracyの出力\n",
    "    score = cross_val_score(clf, X, y, n_jobs=-1, cv=10, scoring=make_scorer(f1_score))\n",
    "    accuracy = score.mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116e344-f7fb-4c5f-933c-c11d29635f8b",
   "metadata": {},
   "source": [
    "##　全サンプルでの予測(boruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8c4c65-21b7-4c6f-ac6d-05b0ef9c1d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-11 09:32:42,633]\u001b[0m A new study created in memory with name: no-name-31359920-1ec0-42be-b0e7-645d3bc302b3\u001b[0m\n",
      "/root/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/root/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/root/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/root/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/root/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/root/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "\u001b[32m[I 2022-08-11 09:33:23,726]\u001b[0m Trial 0 finished with value: 0.713597642177245 and parameters: {'n_estimators': 548, 'criterion': 'log_loss', 'max_depth': 2, 'max_leaf_nodes': 14, 'max_features': 'log2'}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:33:44,311]\u001b[0m Trial 1 finished with value: 0.713557797004337 and parameters: {'n_estimators': 579, 'criterion': 'gini', 'max_depth': 2, 'max_leaf_nodes': 23, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:35:07,019]\u001b[0m Trial 2 finished with value: 0.7055980179639783 and parameters: {'n_estimators': 818, 'criterion': 'log_loss', 'max_depth': 27, 'max_leaf_nodes': 35, 'max_features': 'log2'}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:35:43,449]\u001b[0m Trial 3 finished with value: 0.7011178046392403 and parameters: {'n_estimators': 260, 'criterion': 'gini', 'max_depth': 13, 'max_leaf_nodes': 12, 'max_features': None}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:37:32,461]\u001b[0m Trial 4 finished with value: 0.6968557847309766 and parameters: {'n_estimators': 982, 'criterion': 'entropy', 'max_depth': 20, 'max_leaf_nodes': 64, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:38:06,892]\u001b[0m Trial 5 finished with value: 0.7001654029842268 and parameters: {'n_estimators': 549, 'criterion': 'gini', 'max_depth': 30, 'max_leaf_nodes': 98, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:38:34,321]\u001b[0m Trial 6 finished with value: 0.7016565746518284 and parameters: {'n_estimators': 361, 'criterion': 'gini', 'max_depth': 2, 'max_leaf_nodes': 52, 'max_features': None}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:38:49,090]\u001b[0m Trial 7 finished with value: 0.6949349021793145 and parameters: {'n_estimators': 151, 'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 37, 'max_features': 'log2'}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:39:23,442]\u001b[0m Trial 8 finished with value: 0.7032176812494315 and parameters: {'n_estimators': 182, 'criterion': 'gini', 'max_depth': 20, 'max_leaf_nodes': 35, 'max_features': None}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:39:31,353]\u001b[0m Trial 9 finished with value: 0.7005089777722325 and parameters: {'n_estimators': 97, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 81, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:40:22,034]\u001b[0m Trial 10 finished with value: 0.7113053378949248 and parameters: {'n_estimators': 545, 'criterion': 'log_loss', 'max_depth': 7, 'max_leaf_nodes': 67, 'max_features': 'log2'}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:43:19,975]\u001b[0m Trial 11 finished with value: 0.70429543846501 and parameters: {'n_estimators': 661, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 71, 'max_features': None}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:47:02,728]\u001b[0m Trial 12 finished with value: 0.6986184033523246 and parameters: {'n_estimators': 977, 'criterion': 'gini', 'max_depth': 39, 'max_leaf_nodes': 96, 'max_features': None}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:49:15,205]\u001b[0m Trial 13 finished with value: 0.697888921941943 and parameters: {'n_estimators': 279, 'criterion': 'entropy', 'max_depth': 19, 'max_leaf_nodes': 54, 'max_features': None}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:49:35,986]\u001b[0m Trial 14 finished with value: 0.7129879191388777 and parameters: {'n_estimators': 409, 'criterion': 'entropy', 'max_depth': 2, 'max_leaf_nodes': 29, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:49:59,351]\u001b[0m Trial 15 finished with value: 0.7060435590163967 and parameters: {'n_estimators': 290, 'criterion': 'log_loss', 'max_depth': 49, 'max_leaf_nodes': 12, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.713597642177245.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:53:18,305]\u001b[0m Trial 16 finished with value: 0.7168342659545279 and parameters: {'n_estimators': 944, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 40, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:58:04,609]\u001b[0m Trial 17 finished with value: 0.7068696536232418 and parameters: {'n_estimators': 720, 'criterion': 'log_loss', 'max_depth': 7, 'max_leaf_nodes': 37, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:58:30,501]\u001b[0m Trial 18 finished with value: 0.7153571309636528 and parameters: {'n_estimators': 497, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 36, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 09:59:39,594]\u001b[0m Trial 19 finished with value: 0.699404186568694 and parameters: {'n_estimators': 141, 'criterion': 'log_loss', 'max_depth': 29, 'max_leaf_nodes': 53, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:01:05,569]\u001b[0m Trial 20 finished with value: 0.7071852796536742 and parameters: {'n_estimators': 710, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 86, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:03:08,037]\u001b[0m Trial 21 finished with value: 0.6942995410562504 and parameters: {'n_estimators': 260, 'criterion': 'log_loss', 'max_depth': 43, 'max_leaf_nodes': 50, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:03:25,680]\u001b[0m Trial 22 finished with value: 0.7045625439348739 and parameters: {'n_estimators': 170, 'criterion': 'log_loss', 'max_depth': 7, 'max_leaf_nodes': 86, 'max_features': 'sqrt'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:05:02,899]\u001b[0m Trial 23 finished with value: 0.7076209531931464 and parameters: {'n_estimators': 980, 'criterion': 'log_loss', 'max_depth': 26, 'max_leaf_nodes': 31, 'max_features': 'sqrt'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:06:52,768]\u001b[0m Trial 24 finished with value: 0.706347289197607 and parameters: {'n_estimators': 895, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 55, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:07:46,962]\u001b[0m Trial 25 finished with value: 0.7124678357136893 and parameters: {'n_estimators': 956, 'criterion': 'gini', 'max_depth': 45, 'max_leaf_nodes': 22, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:08:23,139]\u001b[0m Trial 26 finished with value: 0.7128932911207589 and parameters: {'n_estimators': 705, 'criterion': 'entropy', 'max_depth': 2, 'max_leaf_nodes': 13, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:09:56,288]\u001b[0m Trial 27 finished with value: 0.7008363951995984 and parameters: {'n_estimators': 833, 'criterion': 'log_loss', 'max_depth': 31, 'max_leaf_nodes': 57, 'max_features': 'sqrt'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:10:46,697]\u001b[0m Trial 28 finished with value: 0.7086922242740971 and parameters: {'n_estimators': 862, 'criterion': 'gini', 'max_depth': 33, 'max_leaf_nodes': 45, 'max_features': 'sqrt'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:16:03,964]\u001b[0m Trial 29 finished with value: 0.7040665603018603 and parameters: {'n_estimators': 709, 'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 40, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:17:14,008]\u001b[0m Trial 30 finished with value: 0.7121605252211318 and parameters: {'n_estimators': 967, 'criterion': 'log_loss', 'max_depth': 26, 'max_leaf_nodes': 8, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:17:45,147]\u001b[0m Trial 31 finished with value: 0.711350003366131 and parameters: {'n_estimators': 682, 'criterion': 'gini', 'max_depth': 2, 'max_leaf_nodes': 34, 'max_features': 'sqrt'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:19:33,839]\u001b[0m Trial 32 finished with value: 0.708571382572144 and parameters: {'n_estimators': 929, 'criterion': 'log_loss', 'max_depth': 9, 'max_leaf_nodes': 51, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:20:05,700]\u001b[0m Trial 33 finished with value: 0.7021839987803767 and parameters: {'n_estimators': 443, 'criterion': 'gini', 'max_depth': 24, 'max_leaf_nodes': 29, 'max_features': 'sqrt'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:20:17,923]\u001b[0m Trial 34 finished with value: 0.7082555023418811 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': 2, 'max_leaf_nodes': 58, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:20:35,231]\u001b[0m Trial 35 finished with value: 0.7082713520740078 and parameters: {'n_estimators': 374, 'criterion': 'gini', 'max_depth': 2, 'max_leaf_nodes': 7, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:21:16,199]\u001b[0m Trial 36 finished with value: 0.6954029130260246 and parameters: {'n_estimators': 250, 'criterion': 'log_loss', 'max_depth': 2, 'max_leaf_nodes': 18, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:23:12,334]\u001b[0m Trial 37 finished with value: 0.7023064684310321 and parameters: {'n_estimators': 218, 'criterion': 'entropy', 'max_depth': 24, 'max_leaf_nodes': 93, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:24:32,712]\u001b[0m Trial 38 finished with value: 0.6945536730401269 and parameters: {'n_estimators': 603, 'criterion': 'log_loss', 'max_depth': 39, 'max_leaf_nodes': 98, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:24:48,380]\u001b[0m Trial 39 finished with value: 0.7143576689209672 and parameters: {'n_estimators': 237, 'criterion': 'log_loss', 'max_depth': 3, 'max_leaf_nodes': 84, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:26:08,080]\u001b[0m Trial 40 finished with value: 0.6996998890164541 and parameters: {'n_estimators': 147, 'criterion': 'log_loss', 'max_depth': 18, 'max_leaf_nodes': 70, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:26:14,025]\u001b[0m Trial 41 finished with value: 0.696996123129373 and parameters: {'n_estimators': 75, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 56, 'max_features': 'sqrt'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:26:24,430]\u001b[0m Trial 42 finished with value: 0.7134382601525459 and parameters: {'n_estimators': 157, 'criterion': 'entropy', 'max_depth': 2, 'max_leaf_nodes': 39, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:27:41,814]\u001b[0m Trial 43 finished with value: 0.7019788846556426 and parameters: {'n_estimators': 665, 'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 53, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:28:20,412]\u001b[0m Trial 44 finished with value: 0.7142951399791141 and parameters: {'n_estimators': 603, 'criterion': 'entropy', 'max_depth': 2, 'max_leaf_nodes': 96, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:34:56,860]\u001b[0m Trial 45 finished with value: 0.6984948620032125 and parameters: {'n_estimators': 707, 'criterion': 'entropy', 'max_depth': 43, 'max_leaf_nodes': 80, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:36:05,203]\u001b[0m Trial 46 finished with value: 0.7037650681362331 and parameters: {'n_estimators': 814, 'criterion': 'gini', 'max_depth': 23, 'max_leaf_nodes': 53, 'max_features': 'sqrt'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:37:08,438]\u001b[0m Trial 47 finished with value: 0.7107558628286049 and parameters: {'n_estimators': 909, 'criterion': 'log_loss', 'max_depth': 2, 'max_leaf_nodes': 39, 'max_features': 'sqrt'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:37:24,747]\u001b[0m Trial 48 finished with value: 0.715032865488746 and parameters: {'n_estimators': 336, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 23, 'max_features': 'sqrt'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:39:05,062]\u001b[0m Trial 49 finished with value: 0.7053983698306523 and parameters: {'n_estimators': 412, 'criterion': 'gini', 'max_depth': 9, 'max_leaf_nodes': 81, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:39:10,617]\u001b[0m Trial 50 finished with value: 0.6849638667796027 and parameters: {'n_estimators': 77, 'criterion': 'gini', 'max_depth': 18, 'max_leaf_nodes': 97, 'max_features': 'sqrt'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:39:31,551]\u001b[0m Trial 51 finished with value: 0.7041001415157391 and parameters: {'n_estimators': 188, 'criterion': 'log_loss', 'max_depth': 9, 'max_leaf_nodes': 46, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:39:59,713]\u001b[0m Trial 52 finished with value: 0.7070457004750537 and parameters: {'n_estimators': 159, 'criterion': 'gini', 'max_depth': 6, 'max_leaf_nodes': 90, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:40:10,289]\u001b[0m Trial 53 finished with value: 0.6976454755399997 and parameters: {'n_estimators': 29, 'criterion': 'log_loss', 'max_depth': 8, 'max_leaf_nodes': 8, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:41:15,969]\u001b[0m Trial 54 finished with value: 0.701515216923251 and parameters: {'n_estimators': 879, 'criterion': 'gini', 'max_depth': 21, 'max_leaf_nodes': 69, 'max_features': 'sqrt'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:41:35,731]\u001b[0m Trial 55 finished with value: 0.7103948265066755 and parameters: {'n_estimators': 350, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 56, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:42:42,448]\u001b[0m Trial 56 finished with value: 0.7003998099598032 and parameters: {'n_estimators': 136, 'criterion': 'log_loss', 'max_depth': 11, 'max_leaf_nodes': 25, 'max_features': None}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:43:33,746]\u001b[0m Trial 57 finished with value: 0.7117759226745346 and parameters: {'n_estimators': 453, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 27, 'max_features': 'log2'}. Best is trial 16 with value: 0.7168342659545279.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:44:28,152]\u001b[0m Trial 58 finished with value: 0.7177175017522909 and parameters: {'n_estimators': 945, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 44, 'max_features': 'log2'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:44:53,700]\u001b[0m Trial 59 finished with value: 0.712275047851749 and parameters: {'n_estimators': 413, 'criterion': 'log_loss', 'max_depth': 2, 'max_leaf_nodes': 68, 'max_features': 'log2'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:45:10,498]\u001b[0m Trial 60 finished with value: 0.7108543758211943 and parameters: {'n_estimators': 256, 'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 78, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:47:01,734]\u001b[0m Trial 61 finished with value: 0.7008777900692117 and parameters: {'n_estimators': 683, 'criterion': 'log_loss', 'max_depth': 2, 'max_leaf_nodes': 67, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:48:57,973]\u001b[0m Trial 62 finished with value: 0.694538392684067 and parameters: {'n_estimators': 231, 'criterion': 'entropy', 'max_depth': 16, 'max_leaf_nodes': 62, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:49:04,510]\u001b[0m Trial 63 finished with value: 0.6977021203353487 and parameters: {'n_estimators': 30, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 90, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:49:29,566]\u001b[0m Trial 64 finished with value: 0.710487528709088 and parameters: {'n_estimators': 527, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 11, 'max_features': 'log2'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:51:43,522]\u001b[0m Trial 65 finished with value: 0.6981351074613038 and parameters: {'n_estimators': 293, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 84, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:54:45,682]\u001b[0m Trial 66 finished with value: 0.7081515589595118 and parameters: {'n_estimators': 773, 'criterion': 'gini', 'max_depth': 44, 'max_leaf_nodes': 71, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:58:12,634]\u001b[0m Trial 67 finished with value: 0.6998356982153366 and parameters: {'n_estimators': 412, 'criterion': 'log_loss', 'max_depth': 41, 'max_leaf_nodes': 48, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:58:59,708]\u001b[0m Trial 68 finished with value: 0.716178120670086 and parameters: {'n_estimators': 440, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 42, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 10:59:52,033]\u001b[0m Trial 69 finished with value: 0.709553377874227 and parameters: {'n_estimators': 957, 'criterion': 'entropy', 'max_depth': 2, 'max_leaf_nodes': 25, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:00:58,720]\u001b[0m Trial 70 finished with value: 0.6953651150618183 and parameters: {'n_estimators': 249, 'criterion': 'gini', 'max_depth': 31, 'max_leaf_nodes': 86, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:02:59,025]\u001b[0m Trial 71 finished with value: 0.7070051515234533 and parameters: {'n_estimators': 488, 'criterion': 'gini', 'max_depth': 14, 'max_leaf_nodes': 72, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:04:13,534]\u001b[0m Trial 72 finished with value: 0.7038874440198354 and parameters: {'n_estimators': 654, 'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 40, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:05:52,012]\u001b[0m Trial 73 finished with value: 0.7098506331158709 and parameters: {'n_estimators': 829, 'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 62, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:07:19,436]\u001b[0m Trial 74 finished with value: 0.7154879198520139 and parameters: {'n_estimators': 931, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 83, 'max_features': 'log2'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:09:30,878]\u001b[0m Trial 75 finished with value: 0.7066361480298461 and parameters: {'n_estimators': 633, 'criterion': 'gini', 'max_depth': 19, 'max_leaf_nodes': 30, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:10:15,790]\u001b[0m Trial 76 finished with value: 0.7081142196826387 and parameters: {'n_estimators': 468, 'criterion': 'log_loss', 'max_depth': 6, 'max_leaf_nodes': 78, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:11:29,213]\u001b[0m Trial 77 finished with value: 0.7045791573292083 and parameters: {'n_estimators': 518, 'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 100, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:12:02,891]\u001b[0m Trial 78 finished with value: 0.7149633667947126 and parameters: {'n_estimators': 484, 'criterion': 'log_loss', 'max_depth': 8, 'max_leaf_nodes': 4, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:12:16,310]\u001b[0m Trial 79 finished with value: 0.7066491385055039 and parameters: {'n_estimators': 114, 'criterion': 'log_loss', 'max_depth': 9, 'max_leaf_nodes': 72, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:12:25,301]\u001b[0m Trial 80 finished with value: 0.7104378750206676 and parameters: {'n_estimators': 131, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 51, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:13:45,611]\u001b[0m Trial 81 finished with value: 0.7120979659605915 and parameters: {'n_estimators': 764, 'criterion': 'entropy', 'max_depth': 16, 'max_leaf_nodes': 19, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:15:00,379]\u001b[0m Trial 82 finished with value: 0.7035981804736391 and parameters: {'n_estimators': 650, 'criterion': 'entropy', 'max_depth': 30, 'max_leaf_nodes': 34, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:15:33,181]\u001b[0m Trial 83 finished with value: 0.7155133581748601 and parameters: {'n_estimators': 361, 'criterion': 'log_loss', 'max_depth': 4, 'max_leaf_nodes': 63, 'max_features': 'log2'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:15:37,902]\u001b[0m Trial 84 finished with value: 0.6709644611145802 and parameters: {'n_estimators': 57, 'criterion': 'gini', 'max_depth': 15, 'max_leaf_nodes': 95, 'max_features': 'log2'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:16:11,876]\u001b[0m Trial 85 finished with value: 0.7148581177716518 and parameters: {'n_estimators': 401, 'criterion': 'log_loss', 'max_depth': 4, 'max_leaf_nodes': 13, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:20:05,106]\u001b[0m Trial 86 finished with value: 0.7055844032768855 and parameters: {'n_estimators': 646, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 71, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:20:42,700]\u001b[0m Trial 87 finished with value: 0.7119392002303303 and parameters: {'n_estimators': 422, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 90, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:24:59,692]\u001b[0m Trial 88 finished with value: 0.7041108487785905 and parameters: {'n_estimators': 530, 'criterion': 'entropy', 'max_depth': 8, 'max_leaf_nodes': 78, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:27:41,276]\u001b[0m Trial 89 finished with value: 0.7003169586943789 and parameters: {'n_estimators': 912, 'criterion': 'log_loss', 'max_depth': 2, 'max_leaf_nodes': 87, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:31:36,079]\u001b[0m Trial 90 finished with value: 0.7050538308259645 and parameters: {'n_estimators': 477, 'criterion': 'log_loss', 'max_depth': 8, 'max_leaf_nodes': 76, 'max_features': None}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:32:13,441]\u001b[0m Trial 91 finished with value: 0.7099007550539655 and parameters: {'n_estimators': 848, 'criterion': 'gini', 'max_depth': 2, 'max_leaf_nodes': 100, 'max_features': 'log2'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:32:38,902]\u001b[0m Trial 92 finished with value: 0.7078543068355172 and parameters: {'n_estimators': 247, 'criterion': 'log_loss', 'max_depth': 15, 'max_leaf_nodes': 20, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:33:39,687]\u001b[0m Trial 93 finished with value: 0.6986916921738786 and parameters: {'n_estimators': 457, 'criterion': 'entropy', 'max_depth': 11, 'max_leaf_nodes': 68, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:34:18,510]\u001b[0m Trial 94 finished with value: 0.7098953192162641 and parameters: {'n_estimators': 797, 'criterion': 'gini', 'max_depth': 2, 'max_leaf_nodes': 16, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:34:35,090]\u001b[0m Trial 95 finished with value: 0.7150759760457973 and parameters: {'n_estimators': 236, 'criterion': 'log_loss', 'max_depth': 3, 'max_leaf_nodes': 11, 'max_features': 'sqrt'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:35:05,026]\u001b[0m Trial 96 finished with value: 0.7148144647561064 and parameters: {'n_estimators': 370, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 75, 'max_features': 'log2'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:35:11,955]\u001b[0m Trial 97 finished with value: 0.6991336393953598 and parameters: {'n_estimators': 80, 'criterion': 'log_loss', 'max_depth': 4, 'max_leaf_nodes': 44, 'max_features': 'log2'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:36:22,983]\u001b[0m Trial 98 finished with value: 0.7134239146643335 and parameters: {'n_estimators': 725, 'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 17, 'max_features': 'log2'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n",
      "\u001b[32m[I 2022-08-11 11:37:21,225]\u001b[0m Trial 99 finished with value: 0.7137909753987921 and parameters: {'n_estimators': 972, 'criterion': 'gini', 'max_depth': 43, 'max_leaf_nodes': 16, 'max_features': 'log2'}. Best is trial 58 with value: 0.7177175017522909.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "year = 15\n",
    "X_train_tmp = df_dict[\"chi2\"][\"boruta\"][\"train\"][\"X{0:0=2}\".format(year)]\n",
    "y_train_tmp = df_dict[\"chi2\"][\"boruta\"][\"train\"][\"y{0:0=2}\".format(year)]\n",
    "X_test_tmp = df_dict[\"chi2\"][\"boruta\"][\"test\"][\"X{0:0=2}\".format(year)]\n",
    "y_test_tmp = df_dict[\"chi2\"][\"boruta\"][\"test\"][\"y{0:0=2}\".format(year)]\n",
    "\n",
    "X, y = X_train_tmp.copy(), y_train_tmp.copy()\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\", sampler=optuna.samplers.RandomSampler(seed=SEED)\n",
    ")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "989b5595-b630-48cd-8428-38fcc7fef43a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value is : \n",
      " 0.7177175017522909\n",
      "The best parameters are : \n",
      " {'n_estimators': 945, 'criterion': 'gini', 'max_depth': 3, 'max_leaf_nodes': 44, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "# 最も良いパラメータ\n",
    "print(f\"The best value is : \\n {study.best_value}\")\n",
    "print(f\"The best parameters are : \\n {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99124294-1258-45b8-8890-5904fdfe4fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning前\n",
      "accuracy:  0.6201550387596899\n",
      "precision:  0.625\n",
      "recall:  0.7246376811594203\n",
      "f1 score:  0.6711409395973154\n",
      "tuning後\n",
      "accuracy:  0.6782945736434108\n",
      "precision:  0.655367231638418\n",
      "recall:  0.8405797101449275\n",
      "f1 score:  0.7365079365079366\n"
     ]
    }
   ],
   "source": [
    "print(\"tuning前\")\n",
    "rf = RandomForestClassifier(random_state=SEED)\n",
    "rf.fit(X_train_tmp, y_train_tmp)\n",
    "pred_tmp = rf.predict(X_test_tmp)\n",
    "show_scores(y_test_tmp, pred_tmp)\n",
    "\n",
    "print(\"tuning後\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=705,\n",
    "    criterion=\"entropy\",\n",
    "    max_depth=2,\n",
    "    max_leaf_nodes=13,\n",
    "    max_features=\"log2\",\n",
    "    random_state=SEED,\n",
    ")\n",
    "rf.fit(X_train_tmp, y_train_tmp)\n",
    "pred_tmp = rf.predict(X_test_tmp)\n",
    "show_scores(y_test_tmp, pred_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "197342bf-336d-4492-83eb-c0adeed22412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/optuna/visualization/_plotly_imports.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m try_import() \u001b[38;5;28;01mas\u001b[39;00m _imports:  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m plotly_version\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# optunaの過程を可視化\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_optimization_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/optuna/visualization/_optimization_history.py:73\u001b[0m, in \u001b[0;36mplot_optimization_history\u001b[0;34m(study, target, target_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_optimization_history\u001b[39m(\n\u001b[1;32m     23\u001b[0m     study: Study,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m     25\u001b[0m     target: Optional[Callable[[FrozenTrial], \u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     26\u001b[0m     target_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjective Value\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgo.Figure\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124;03m\"\"\"Plot optimization history of all trials in a study.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m            optimization.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[43m_imports\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     _check_plot_args(study, target, target_name)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_optimization_history_plot(study, target, target_name)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/optuna/_imports.py:86\u001b[0m, in \u001b[0;36m_DeferredImportExceptionContextManager.check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     exc_value, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc_value\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "# optunaの過程を可視化\n",
    "optuna.visualization.plot_optimization_history(study).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376cae4-6bff-47fe-bbea-dc54eed5d432",
   "metadata": {},
   "source": [
    "## subtype毎の予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c65e305b-39d9-4237-8a55-36c1281df855",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====05=====05=====05=====05=====05=====05=====05=====05=====05=====05\n",
      "--------------------------------------------------\n",
      "claudin-low\n",
      "tuning前\n",
      "accuracy:  0.7954545454545454\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1 score:  0.0\n",
      "tuning後\n",
      "accuracy:  0.8181818181818182\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1 score:  0.0\n",
      "--------------------------------------------------\n",
      "LumA\n",
      "tuning前\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9261744966442953\n",
      "precision:  0.3333333333333333\n",
      "recall:  0.1\n",
      "f1 score:  0.15384615384615383\n",
      "tuning後\n",
      "accuracy:  0.9328859060402684\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1 score:  0.0\n",
      "--------------------------------------------------\n",
      "LumB\n",
      "tuning前\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8260869565217391\n",
      "precision:  0.3333333333333333\n",
      "recall:  0.05263157894736842\n",
      "f1 score:  0.09090909090909091\n",
      "tuning後\n",
      "accuracy:  0.8347826086956521\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1 score:  0.0\n",
      "--------------------------------------------------\n",
      "Her2\n",
      "tuning前\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7058823529411765\n",
      "precision:  0.6666666666666666\n",
      "recall:  0.3333333333333333\n",
      "f1 score:  0.4444444444444444\n",
      "tuning後\n",
      "accuracy:  0.6470588235294118\n",
      "precision:  0.5\n",
      "recall:  0.16666666666666666\n",
      "f1 score:  0.25\n",
      "--------------------------------------------------\n",
      "Normal\n",
      "tuning前\n",
      "accuracy:  0.7714285714285715\n",
      "precision:  0.25\n",
      "recall:  0.5\n",
      "f1 score:  0.3333333333333333\n",
      "tuning後\n",
      "accuracy:  0.7428571428571429\n",
      "precision:  0.14285714285714285\n",
      "recall:  0.25\n",
      "f1 score:  0.18181818181818182\n",
      "--------------------------------------------------\n",
      "Basal\n",
      "tuning前\n",
      "accuracy:  0.4523809523809524\n",
      "precision:  0.3\n",
      "recall:  0.15789473684210525\n",
      "f1 score:  0.20689655172413793\n",
      "tuning後\n",
      "accuracy:  0.47619047619047616\n",
      "precision:  0.2857142857142857\n",
      "recall:  0.10526315789473684\n",
      "f1 score:  0.15384615384615385\n",
      "=====10=====10=====10=====10=====10=====10=====10=====10=====10=====10\n",
      "--------------------------------------------------\n",
      "claudin-low\n",
      "tuning前\n",
      "accuracy:  0.6285714285714286\n",
      "precision:  0.42857142857142855\n",
      "recall:  0.25\n",
      "f1 score:  0.3157894736842105\n",
      "tuning後\n",
      "accuracy:  0.6571428571428571\n",
      "precision:  0.5\n",
      "recall:  0.16666666666666666\n",
      "f1 score:  0.25\n",
      "--------------------------------------------------\n",
      "LumA\n",
      "tuning前\n",
      "accuracy:  0.8392857142857143\n",
      "precision:  1.0\n",
      "recall:  0.05263157894736842\n",
      "f1 score:  0.1\n",
      "tuning後\n",
      "accuracy:  0.8303571428571429\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1 score:  0.0\n",
      "--------------------------------------------------\n",
      "LumB\n",
      "tuning前\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.5268817204301075\n",
      "precision:  0.3142857142857143\n",
      "recall:  0.3548387096774194\n",
      "f1 score:  0.3333333333333333\n",
      "tuning後\n",
      "accuracy:  0.5913978494623656\n",
      "precision:  0.36\n",
      "recall:  0.2903225806451613\n",
      "f1 score:  0.3214285714285714\n",
      "--------------------------------------------------\n",
      "Her2\n",
      "tuning前\n",
      "accuracy:  0.574468085106383\n",
      "precision:  0.5517241379310345\n",
      "recall:  0.6956521739130435\n",
      "f1 score:  0.6153846153846154\n",
      "tuning後\n",
      "accuracy:  0.5319148936170213\n",
      "precision:  0.5142857142857142\n",
      "recall:  0.782608695652174\n",
      "f1 score:  0.6206896551724138\n",
      "--------------------------------------------------\n",
      "Normal\n",
      "tuning前\n",
      "accuracy:  0.6666666666666666\n",
      "precision:  0.45454545454545453\n",
      "recall:  0.7142857142857143\n",
      "f1 score:  0.5555555555555556\n",
      "tuning後\n",
      "accuracy:  0.7083333333333334\n",
      "precision:  0.5\n",
      "recall:  0.7142857142857143\n",
      "f1 score:  0.588235294117647\n",
      "--------------------------------------------------\n",
      "Basal\n",
      "tuning前\n",
      "accuracy:  0.5263157894736842\n",
      "precision:  0.6923076923076923\n",
      "recall:  0.391304347826087\n",
      "f1 score:  0.5\n",
      "tuning後\n",
      "accuracy:  0.5263157894736842\n",
      "precision:  0.7272727272727273\n",
      "recall:  0.34782608695652173\n",
      "f1 score:  0.4705882352941176\n",
      "=====15=====15=====15=====15=====15=====15=====15=====15=====15=====15\n",
      "--------------------------------------------------\n",
      "claudin-low\n",
      "tuning前\n",
      "accuracy:  0.6\n",
      "precision:  0.5714285714285714\n",
      "recall:  0.5714285714285714\n",
      "f1 score:  0.5714285714285714\n",
      "tuning後\n",
      "accuracy:  0.6\n",
      "precision:  0.5714285714285714\n",
      "recall:  0.5714285714285714\n",
      "f1 score:  0.5714285714285714\n",
      "--------------------------------------------------\n",
      "LumA\n",
      "tuning前\n",
      "accuracy:  0.6142857142857143\n",
      "precision:  0.42857142857142855\n",
      "recall:  0.24\n",
      "f1 score:  0.30769230769230765\n",
      "tuning後\n",
      "accuracy:  0.6714285714285714\n",
      "precision:  0.625\n",
      "recall:  0.2\n",
      "f1 score:  0.30303030303030304\n",
      "--------------------------------------------------\n",
      "LumB\n",
      "tuning前\n",
      "accuracy:  0.6857142857142857\n",
      "precision:  0.6792452830188679\n",
      "recall:  0.8780487804878049\n",
      "f1 score:  0.7659574468085106\n",
      "tuning後\n",
      "accuracy:  0.6714285714285714\n",
      "precision:  0.640625\n",
      "recall:  1.0\n",
      "f1 score:  0.780952380952381\n",
      "--------------------------------------------------\n",
      "Her2\n",
      "tuning前\n",
      "accuracy:  0.7105263157894737\n",
      "precision:  0.75\n",
      "recall:  0.84\n",
      "f1 score:  0.7924528301886793\n",
      "tuning後\n",
      "accuracy:  0.6578947368421053\n",
      "precision:  0.6578947368421053\n",
      "recall:  1.0\n",
      "f1 score:  0.7936507936507937\n",
      "--------------------------------------------------\n",
      "Normal\n",
      "tuning前\n",
      "accuracy:  0.7058823529411765\n",
      "precision:  0.7272727272727273\n",
      "recall:  0.8\n",
      "f1 score:  0.761904761904762\n",
      "tuning後\n",
      "accuracy:  0.7058823529411765\n",
      "precision:  0.7272727272727273\n",
      "recall:  0.8\n",
      "f1 score:  0.761904761904762\n",
      "--------------------------------------------------\n",
      "Basal\n",
      "tuning前\n",
      "accuracy:  0.5757575757575758\n",
      "precision:  0.7142857142857143\n",
      "recall:  0.6521739130434783\n",
      "f1 score:  0.6818181818181819\n",
      "tuning後\n",
      "accuracy:  0.5757575757575758\n",
      "precision:  0.7368421052631579\n",
      "recall:  0.6086956521739131\n",
      "f1 score:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "for year in range(5, 16, 5):  # 予後年数毎のループ\n",
    "    print(\"====={0:0=2}\".format(year) * 10)\n",
    "\n",
    "    for subtype in pd.read_pickle(\n",
    "        config.INTERIM_PICKLE_PREPROCESSED_PROGNOSIS_CROSS_DIR + \"/df_cross.pkl\"\n",
    "    )[\"CLAUDIN_SUBTYPE\"].unique():\n",
    "        print(\"-----\" * 10)\n",
    "        print(subtype)\n",
    "        X_train_tmp = df_dict[\"chi2\"][\"claudin_subtype\"][\"train\"][\n",
    "            \"X{0:0=2}_{1}\".format(year, subtype)\n",
    "        ]\n",
    "        y_train_tmp = df_dict[\"chi2\"][\"claudin_subtype\"][\"train\"][\n",
    "            \"y{0:0=2}_{1}\".format(year, subtype)\n",
    "        ]\n",
    "        X_test_tmp = df_dict[\"chi2\"][\"claudin_subtype\"][\"test\"][\n",
    "            \"X{0:0=2}_{1}\".format(year, subtype)\n",
    "        ]\n",
    "        y_test_tmp = df_dict[\"chi2\"][\"claudin_subtype\"][\"test\"][\n",
    "            \"y{0:0=2}_{1}\".format(year, subtype)\n",
    "        ]\n",
    "        assert X_train_tmp.shape[0] == y_train_tmp.shape[0], \"train size is incorrect\"\n",
    "        assert X_test_tmp.shape[0] == y_test_tmp.shape[0], \"test size is incorrect\"\n",
    "\n",
    "        print(\"tuning前\")\n",
    "        rf = RandomForestClassifier(random_state=SEED)\n",
    "        rf.fit(X_train_tmp, y_train_tmp)\n",
    "        pred_tmp = rf.predict(X_test_tmp)\n",
    "        show_scores(y_test_tmp, pred_tmp)\n",
    "\n",
    "        print(\"tuning後\")\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=705,\n",
    "            criterion=\"entropy\",\n",
    "            max_depth=2,\n",
    "            max_leaf_nodes=13,\n",
    "            max_features=\"log2\",\n",
    "            random_state=SEED,\n",
    "        )\n",
    "        rf.fit(X_train_tmp, y_train_tmp)\n",
    "        pred_tmp = rf.predict(X_test_tmp)\n",
    "        show_scores(y_test_tmp, pred_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f8458-a720-4986-8e10-e5ece94ed24f",
   "metadata": {},
   "source": [
    "### lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19555b1a-616b-4947-9df1-75d7b01f6006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 100, 300),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 50),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1e-1),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 1000),\n",
    "    }\n",
    "    clf = LGBMClassifier(boosting_type=\"gbdt\", **params, random_state=SEED)\n",
    "    # 10分割交差検証によるテストデータのaccuracyの出力\n",
    "    score = cross_val_score(clf, X, y, n_jobs=-1, cv=10)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "year = 15\n",
    "X_train_tmp = df_dict[\"chi2\"][\"boruta\"][\"train\"][\"X{0:0=2}\".format(year)]\n",
    "y_train_tmp = df_dict[\"chi2\"][\"boruta\"][\"train\"][\"y{0:0=2}\".format(year)]\n",
    "X_test_tmp = df_dict[\"chi2\"][\"boruta\"][\"test\"][\"X{0:0=2}\".format(year)]\n",
    "y_test_tmp = df_dict[\"chi2\"][\"boruta\"][\"test\"][\"y{0:0=2}\".format(year)]\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afc9668-b4e0-4337-ae59-e504ff395999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最も良いパラメータ\n",
    "print(f\"The best value is : \\n {study.best_value}\")\n",
    "print(f\"The best parameters are : \\n {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989b763-6277-41fb-b159-45bed6b9fb03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
