{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead5983e-2635-46f5-ad52-741c231e270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(self, X):\n",
    "    \"\"\"Transform X in the existing embedded space back into the input\n",
    "    data space and return that transformed output.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape (n_samples, n_components)\n",
    "        New points to be inverse transformed.\n",
    "    Returns\n",
    "    -------\n",
    "    X_new : array, shape (n_samples, n_features)\n",
    "        Generated data points new data in data space.\n",
    "    \"\"\"\n",
    "\n",
    "    if self._sparse_data:\n",
    "        raise ValueError(\"Inverse transform not available for sparse input.\")\n",
    "    elif self._inverse_distance_func is None:\n",
    "        raise ValueError(\"Inverse transform not available for given metric.\")\n",
    "    elif self.densmap:\n",
    "        raise ValueError(\"Inverse transform not available for densMAP.\")\n",
    "    elif self.n_components >= 8:\n",
    "        warn(\n",
    "            \"Inverse transform works best with low dimensional embeddings.\"\n",
    "            \" Results may be poor, or this approach to inverse transform\"\n",
    "            \" may fail altogether! If you need a high dimensional latent\"\n",
    "            \" space and inverse transform operations consider using an\"\n",
    "            \" autoencoder.\"\n",
    "        )\n",
    "    elif self.transform_mode == \"graph\":\n",
    "        raise ValueError(\"Inverse transform not available for transform_mode = 'graph'\")\n",
    "\n",
    "    X = check_array(X, dtype=np.float32, order=\"C\")\n",
    "    random_state = check_random_state(self.transform_seed)\n",
    "    rng_state = random_state.randint(INT32_MIN, INT32_MAX, 3).astype(np.int64)\n",
    "\n",
    "    # build Delaunay complex (Does this not assume a roughly euclidean output metric)?\n",
    "    deltri = scipy.spatial.Delaunay(\n",
    "        self.embedding_, incremental=True, qhull_options=\"QJ\"\n",
    "    )\n",
    "    neighbors = deltri.simplices[deltri.find_simplex(X)]\n",
    "    adjmat = scipy.sparse.lil_matrix(\n",
    "        (self.embedding_.shape[0], self.embedding_.shape[0]), dtype=int\n",
    "    )\n",
    "    for i in np.arange(0, deltri.simplices.shape[0]):\n",
    "        for j in deltri.simplices[i]:\n",
    "            if j < self.embedding_.shape[0]:\n",
    "                idx = deltri.simplices[i][\n",
    "                    deltri.simplices[i] < self.embedding_.shape[0]\n",
    "                ]\n",
    "                adjmat[j, idx] = 1\n",
    "                adjmat[idx, j] = 1\n",
    "\n",
    "    adjmat = scipy.sparse.csr_matrix(adjmat)\n",
    "\n",
    "    min_vertices = min(self._raw_data.shape[-1], self._raw_data.shape[0])\n",
    "\n",
    "    neighborhood = [\n",
    "        breadth_first_search(adjmat, v[0], min_vertices=min_vertices) for v in neighbors\n",
    "    ]\n",
    "    if callable(self.output_metric):\n",
    "        # need to create another numba.jit-able wrapper for callable\n",
    "        # output_metrics that return a tuple (already checked that it does\n",
    "        # during param validation in `fit` method)\n",
    "        _out_m = self.output_metric\n",
    "\n",
    "        @numba.njit(fastmath=True)\n",
    "        def _output_dist_only(x, y, *kwds):\n",
    "            return _out_m(x, y, *kwds)[0]\n",
    "\n",
    "        dist_only_func = _output_dist_only\n",
    "    elif self.output_metric in dist.named_distances.keys():\n",
    "        dist_only_func = dist.named_distances[self.output_metric]\n",
    "    else:\n",
    "        # shouldn't really ever get here because of checks already performed,\n",
    "        # but works as a failsafe in case attr was altered manually after fitting\n",
    "        raise ValueError(\"Unrecognized output metric: {}\".format(self.output_metric))\n",
    "\n",
    "    dist_args = tuple(self._output_metric_kwds.values())\n",
    "    distances = [\n",
    "        np.array(\n",
    "            [\n",
    "                dist_only_func(X[i], self.embedding_[nb], *dist_args)\n",
    "                for nb in neighborhood[i]\n",
    "            ]\n",
    "        )\n",
    "        for i in range(X.shape[0])\n",
    "    ]\n",
    "    idx = np.array([np.argsort(e)[:min_vertices] for e in distances])\n",
    "\n",
    "    dists_output_space = np.array([distances[i][idx[i]] for i in range(len(distances))])\n",
    "    indices = np.array([neighborhood[i][idx[i]] for i in range(len(neighborhood))])\n",
    "\n",
    "    rows, cols, distances = np.array(\n",
    "        [\n",
    "            [i, indices[i, j], dists_output_space[i, j]]\n",
    "            for i in range(indices.shape[0])\n",
    "            for j in range(min_vertices)\n",
    "        ]\n",
    "    ).T\n",
    "\n",
    "    # calculate membership strength of each edge\n",
    "    weights = 1 / (1 + self._a * distances ** (2 * self._b))\n",
    "\n",
    "    # compute 1-skeleton\n",
    "    # convert 1-skeleton into coo_matrix adjacency matrix\n",
    "    graph = scipy.sparse.coo_matrix(\n",
    "        (weights, (rows, cols)), shape=(X.shape[0], self._raw_data.shape[0])\n",
    "    )\n",
    "\n",
    "    # That lets us do fancy unpacking by reshaping the csr matrix indices\n",
    "    # and data. Doing so relies on the constant degree assumption!\n",
    "    # csr_graph = graph.tocsr()\n",
    "    csr_graph = normalize(graph.tocsr(), norm=\"l1\")\n",
    "    inds = csr_graph.indices.reshape(X.shape[0], min_vertices)\n",
    "    weights = csr_graph.data.reshape(X.shape[0], min_vertices)\n",
    "    inv_transformed_points = init_transform(inds, weights, self._raw_data)\n",
    "\n",
    "    if self.n_epochs is None:\n",
    "        # For smaller datasets we can use more epochs\n",
    "        if graph.shape[0] <= 10000:\n",
    "            n_epochs = 100\n",
    "        else:\n",
    "            n_epochs = 30\n",
    "    else:\n",
    "        n_epochs = int(self.n_epochs // 3.0)\n",
    "\n",
    "    # graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0\n",
    "    # graph.eliminate_zeros()\n",
    "\n",
    "    epochs_per_sample = make_epochs_per_sample(graph.data, n_epochs)\n",
    "\n",
    "    head = graph.row\n",
    "    tail = graph.col\n",
    "    weight = graph.data\n",
    "\n",
    "    inv_transformed_points = optimize_layout_inverse(\n",
    "        inv_transformed_points,\n",
    "        self._raw_data,\n",
    "        head,\n",
    "        tail,\n",
    "        weight,\n",
    "        self._sigmas,\n",
    "        self._rhos,\n",
    "        n_epochs,\n",
    "        graph.shape[1],\n",
    "        epochs_per_sample,\n",
    "        self._a,\n",
    "        self._b,\n",
    "        rng_state,\n",
    "        self.repulsion_strength,\n",
    "        self._initial_alpha / 4.0,\n",
    "        self.negative_sample_rate,\n",
    "        self._inverse_distance_func,\n",
    "        tuple(self._metric_kwds.values()),\n",
    "        verbose=self.verbose,\n",
    "        tqdm_kwds=self.tqdm_kwds,\n",
    "    )\n",
    "\n",
    "    return inv_transformed_points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
