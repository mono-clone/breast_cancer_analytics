{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb93b3cc-7680-4f98-812e-608d9bcfda32",
   "metadata": {},
   "source": [
    "# preprocess of recurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d992235-d9ef-4a88-a47e-2ed687ece7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本的なライブラリ\n",
    "import itertools\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import (\n",
    "    GenericUnivariateSelect,\n",
    "    f_classif,\n",
    "    mutual_info_classif,\n",
    "    chi2,\n",
    ")\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# https://github.com/smazzanti/mrmr\n",
    "# pipでinstallはできたが、そのままimportできなかったので、\n",
    "# ライブラリのソースコードをそのまま環境に設置\n",
    "from libraries.mrmr import mrmr\n",
    "\n",
    "import config\n",
    "import functions\n",
    "\n",
    "SEED = config.SEED\n",
    "THRESHOLD_YEARS = config.THRESHOLD_YEARS\n",
    "THRESHOLD_MONTHS = config.THRESHOLD_MONTHS\n",
    "TARGET_NAME = \"RFS_OVER_{0}MONTHS\".format(THRESHOLD_MONTHS)\n",
    "functions.fix_seed(SEED)\n",
    "\n",
    "\n",
    "# 最大表示列数の指定（ここでは50列を指定）N\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8994dbf-0e36-421e-aed3-8cb4e247aded",
   "metadata": {},
   "source": [
    "# データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af54eb16-b22c-4ec8-b2e2-bd7ce542e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient = pd.read_table(\n",
    "    config.RAW_BRCA_METABRIC_DIR + \"/data_clinical_patient.txt\", header=4\n",
    ")\n",
    "df_sample = pd.read_table(\n",
    "    config.RAW_BRCA_METABRIC_DIR + \"/data_clinical_sample.txt\", header=4\n",
    ")\n",
    "df_clinical = pd.merge(df_patient, df_sample, on=\"PATIENT_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7f963-665a-42c0-a5e0-867c83be3490",
   "metadata": {
    "tags": []
   },
   "source": [
    "## カラムの順序変更（読みやすさのため）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d8c6c4-0913-4782-beb2-2efb2b7b6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_columns(df: pd.DataFrame, regex: str):\n",
    "    # まとめたいcolumnの正規表現を一時退避\n",
    "    _df = df.copy()\n",
    "    df_tmp = _df.filter(regex=regex)\n",
    "    # 元のdfから落とす\n",
    "    _df.drop(df_tmp.columns, axis=1, inplace=True)\n",
    "    # 元のdfに結合\n",
    "    return pd.merge(_df, df_tmp, right_index=True, left_index=True)\n",
    "\n",
    "\n",
    "def sort_columns_by_knowledge(df):\n",
    "    _df = df.copy()\n",
    "    # 癌の種類\n",
    "    _df = align_columns(_df, \"^CANCER_\")\n",
    "    # 重要そう（直感）な特徴量\n",
    "    _df = align_columns(_df, \"^ER_|^HER2_|^TUMOR_\")\n",
    "    # 治療の種類\n",
    "    _df = align_columns(_df, \".*THERAPY$|^BREAST_SURGERY\")\n",
    "    # target系の種類（OS, RFS, VITAL）\n",
    "    _df = align_columns(_df, \"^OS_.*|^RFS_.*|^VITAL_.*\")\n",
    "    return _df\n",
    "\n",
    "\n",
    "df_clinical = sort_columns_by_knowledge(df_clinical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c8d29b-a433-4083-bb05-6f1f277181cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1985, 35)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(524, 35)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データを大きく2つに分割できるので、ここで分割\n",
    "df_MB = df_clinical[df_clinical[\"PATIENT_ID\"].str.contains(\"MB\")]\n",
    "df_MTST = df_clinical[df_clinical[\"PATIENT_ID\"].str.contains(\"MTS-T\")]\n",
    "\n",
    "df_MB.set_index(\"PATIENT_ID\", inplace=True)\n",
    "df_MTST.set_index(\"PATIENT_ID\", inplace=True)\n",
    "\n",
    "display(df_MB.shape, df_MTST.shape)\n",
    "# save\n",
    "functions.make_dir(config.INTERIM_PREPROCESSED_RECURRENCE_DIR)\n",
    "df_clinical.to_pickle(config.INTERIM_PREPROCESSED_RECURRENCE_DIR + \"/df_clinical.pkl\")\n",
    "df_MB.to_pickle(config.INTERIM_PREPROCESSED_RECURRENCE_DIR + \"/df_MB.pkl\")\n",
    "df_MTST.to_pickle(config.INTERIM_PREPROCESSED_RECURRENCE_DIR + \"/df_MTST.pkl\")\n",
    "del df_patient, df_sample, df_clinical, df_MB, df_MTST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bca36f-6dc2-4ff9-9da8-8c819d4fb638",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 臨床データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a32df6-05d6-4499-9064-d1c1c263a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MB = pd.read_pickle(config.INTERIM_PREPROCESSED_RECURRENCE_DIR + \"/df_MB.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a1d298-2049-4fa6-aa8b-d355287ff3e4",
   "metadata": {},
   "source": [
    "## 遺伝子データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67529b1e-6763-4afd-984e-07c3e825583a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1904, 24368)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 遺伝子発現データ\n",
    "# 生の遺伝子発現データ\n",
    "df_mrna_agilent_microarray = pd.read_table(\n",
    "    config.RAW_BRCA_METABRIC_DIR + \"/data_mrna_agilent_microarray.txt\", index_col=0\n",
    ").T\n",
    "df_mrna_agilent_microarray = df_mrna_agilent_microarray.drop(\n",
    "    \"Entrez_Gene_Id\"\n",
    ").sort_index()\n",
    "# zスコア化済み\n",
    "df_mrna_agilent_microarray_zscores_ref_all_samples = pd.read_table(\n",
    "    config.RAW_BRCA_METABRIC_DIR\n",
    "    + \"/data_mrna_agilent_microarray_zscores_ref_all_samples.txt\",\n",
    "    index_col=0,\n",
    ").T\n",
    "df_mrna_agilent_microarray_zscores_ref_all_samples = (\n",
    "    df_mrna_agilent_microarray_zscores_ref_all_samples.drop(\"Entrez_Gene_Id\")\n",
    ").sort_index()\n",
    "\"\"\"\n",
    "# zスコア化（2倍体基準）済み\n",
    "df_mrna_agilent_microarray_zscores_ref_diploid_samples = pd.read_table(\n",
    "    config.RAW_BRCA_METABRIC_DIR\n",
    "    + \"/data_mrna_agilent_microarray_zscores_ref_diploid_samples.txt\",\n",
    "    index_col=0,\n",
    ").T\n",
    "df_mrna_agilent_microarray_zscores_ref_diploid_samples = (\n",
    "    df_mrna_agilent_microarray_zscores_ref_diploid_samples.drop(\"Entrez_Gene_Id\")\n",
    ").sort_index()\n",
    "\n",
    "# cnaデータ\n",
    "df_cna = pd.read_table(config.RAW_BRCA_METABRIC_DIR + \"/data_cna.txt\", index_col=0).T\n",
    "df_cna = df_cna.drop(df_cna.index[0])\n",
    "\n",
    "df_methylation_promoters_rrbs = pd.read_table(\n",
    "    config.RAW_BRCA_METABRIC_DIR + \"/data_methylation_promoters_rrbs.txt\", index_col=0\n",
    ").T.sort_index()\n",
    "\"\"\"\n",
    "\n",
    "dict_gene_expressions = dict(\n",
    "    {\n",
    "        \"mrna_agilent_microarray\": df_mrna_agilent_microarray,\n",
    "        \"mrna_agilent_microarray_zscores_ref_all_samples\": df_mrna_agilent_microarray_zscores_ref_all_samples,\n",
    "        # \"mrna_agilent_microarray_zscores_ref_diploid_samples\": df_mrna_agilent_microarray_zscores_ref_diploid_samples,\n",
    "    }\n",
    ")\n",
    "dict_genes = {\n",
    "    \"mrna_agilent_microarray\": df_mrna_agilent_microarray,\n",
    "    \"mrna_agilent_microarray_zscores_ref_all_samples\": df_mrna_agilent_microarray_zscores_ref_all_samples,\n",
    "    # \"mrna_agilent_microarray_zscores_ref_diploid_samples\": df_mrna_agilent_microarray_zscores_ref_diploid_samples,\n",
    "    # \"cna\": df_cna,\n",
    "    # \"methylation_promoters_rrbs\": df_methylation_promoters_rrbs,\n",
    "}\n",
    "df_mrna_agilent_microarray_zscores_ref_all_samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b5ac2-d843-4e66-99ff-947f3822a874",
   "metadata": {},
   "source": [
    "# 前処理\n",
    "- 目的変数生成\n",
    "- 特徴量生成\n",
    "- 特徴名のrename \n",
    "- 欠損値の削除\n",
    "\n",
    "\n",
    "## 目的変数の生成\n",
    "\n",
    "モデルに入力する段階の仮定として、再発は既に判明している（データ取得時にはすでに手術を終えている状況であり、再発の有無についても見ているため）。\n",
    "そこで、【再発年数が**n年**以内か、以後か】に注目し、RFS_MONTHSから目的変数を生成する。    \n",
    "RFS_MONTHSは非再発者の最終フォローアップまでの月数も記録されているが、そちらはデータフレームを操作するときにRFS_STATUSからフィルタリングする。\n",
    "\n",
    "## 特徴量生成\n",
    "予測の**層別化に必要な特徴を生成**する。\n",
    "\n",
    "**層別化に必要な特徴**\n",
    "- CLAUDIN_SUBTYPE\n",
    "- NPI\n",
    "- TUMOR_SIZE\n",
    "- LYMPH_NODES_EXAMINED_POSITIVE\n",
    "\n",
    "数値データは層別化のためにカテゴリ化を行う。\n",
    "各カテゴリ化の根拠は以下の通り。\n",
    "- NPI：( ノッティンガムの予後指数：https://en.wikipedia.org/wiki/Nottingham_Prognostic_Index )\n",
    "- TUMOR_SIZE：乳癌のステージの定義( https://oshiete-gan.jp/breast/diagnosis/stages/detail.html )\n",
    "- LYMPH_NODES_EXAMINED_POSITIVE：https://medical.nikkeibp.co.jp/leaf/all/cancernavi/news/201403/535575.html\n",
    "\n",
    "## 特徴量名のrename\n",
    "重複した特徴量は別のものとして扱う\n",
    "\n",
    "\n",
    "## 欠損値の削除\n",
    "- 欠損値が多い→特徴量の削除  \n",
    "- 欠損値が少ない→サンプルの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f54d52-bf1a-41da-a455-2ff21eda8056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重複特徴名数（rename前）： 194\n",
      "重複特徴名数（rename後）： 0\n",
      "欠損値が多い特徴個数： 0\n",
      "欠損値が少ない特徴個数： 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_target(target_months: int = THRESHOLD_MONTHS):\n",
    "    # RFS_STATUSのみにnullがあるため、そのデータについては患者データを削除する\n",
    "    df_MB.dropna(subset=\"RFS_STATUS\", inplace=True)\n",
    "    # 予測ラベルを扱いやすい形に変更\n",
    "    df_MB[\"RFS_STATUS\"] = df_MB[\"RFS_STATUS\"].replace(\n",
    "        {\"1:Recurred\": 1, \"0:Not Recurred\": 0}\n",
    "    )\n",
    "    df_MB[TARGET_NAME] = pd.cut(\n",
    "        df_MB[\"RFS_MONTHS\"], [0, target_months, np.inf], labels=[0, 1]\n",
    "    )\n",
    "    df_MB.dropna(inplace=True, subset=TARGET_NAME)\n",
    "\n",
    "\n",
    "def generate_features():\n",
    "    df_MB[\"NPI_CAT\"] = pd.cut(\n",
    "        df_MB.NPI,\n",
    "        [0, 2.0, 2.4, 3.4, 5.4, np.inf],\n",
    "        labels=[\"0.0~2.0\", \"2.0~2.4\", \"2.4~3.4\", \"3.4~5.4\", \"5.4~inf\"],\n",
    "    )\n",
    "    df_MB[\"TUMOR_CAT\"] = pd.cut(\n",
    "        df_MB.TUMOR_SIZE, [0, 20, 50, np.inf], labels=[\"0~20\", \"20~50\", \"50~inf\"]\n",
    "    )\n",
    "    df_MB[\"LYMPH_CAT\"] = pd.cut(\n",
    "        df_MB.LYMPH_NODES_EXAMINED_POSITIVE,\n",
    "        [-np.inf, 0, 3, np.inf],\n",
    "        labels=[\"0\", \"1~3\", \"4~inf\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def rename_duplicatged_columns(df):\n",
    "    _df = df.copy()\n",
    "    # 重複特徴量の確認\n",
    "    print(\n",
    "        \"重複特徴名数（rename前）：\",\n",
    "        _df.columns[_df.columns.duplicated()].value_counts().sum(),\n",
    "    )\n",
    "\n",
    "    cols = pd.Series(_df.columns)\n",
    "    for dup in cols[cols.duplicated()].unique():\n",
    "        cols[cols[cols == dup].index.values.tolist()] = [\n",
    "            dup + \"_\" + str(i) if i != 0 else dup for i in range(sum(cols == dup))\n",
    "        ]\n",
    "\n",
    "    # rename the columns with the cols list.\n",
    "    _df.columns = cols\n",
    "    # 重複特徴量の確認\n",
    "    print(\n",
    "        \"重複特徴名数（rename後）：\",\n",
    "        _df.columns[_df.columns.duplicated()].value_counts().sum(),\n",
    "    )\n",
    "    return _df\n",
    "\n",
    "\n",
    "def drop_null4cols(df):\n",
    "    _df = df.copy()\n",
    "    print(\n",
    "        \"欠損値が多い特徴個数：\",\n",
    "        (_df.isnull().sum() > _df.shape[0] // 10).sum(),\n",
    "    )\n",
    "    features = _df.isnull().sum().sort_values()[::-1]\n",
    "    features.plot()\n",
    "\n",
    "    # 多数の欠損値を持つ特徴\n",
    "    many_null_features = features[_df.isnull().sum() > _df.shape[0] // 10].index\n",
    "    # 多数の欠損値を持つ特徴の削除\n",
    "    _df.drop(many_null_features, axis=1, inplace=True)\n",
    "    return _df\n",
    "\n",
    "\n",
    "def drop_null4raws(df):\n",
    "    _df = df.copy()\n",
    "    print(\n",
    "        \"欠損値が少ない特徴個数：\",\n",
    "        ((_df.isnull().sum() < +_df.shape[0] // 10) & (_df.isnull().sum() > 0)).sum(),\n",
    "    )\n",
    "    features = _df.isnull().sum().sort_values()[::-1]\n",
    "    features.plot()\n",
    "\n",
    "    # 少数の欠損値を持つ特徴\n",
    "    few_null_features = features[\n",
    "        (_df.isnull().sum() <= _df.shape[0] // 10) & (_df.isnull().sum() > 0)\n",
    "    ]\n",
    "    # 少数の欠損値の遺伝子発現を持つ患者ID\n",
    "    list_patient_id_contains_null_expressions = list()\n",
    "    for name in few_null_features.index:\n",
    "        for patient_id in _df[_df[name].isnull()].index:\n",
    "            list_patient_id_contains_null_expressions.append(patient_id)\n",
    "\n",
    "    # 少数の欠損値の遺伝子発現を持つ患者の削除\n",
    "    _df.drop(list_patient_id_contains_null_expressions, inplace=True)\n",
    "    return _df\n",
    "\n",
    "\n",
    "# 臨床データ\n",
    "generate_target()\n",
    "generate_features()\n",
    "# 遺伝子データ\n",
    "df_gene_expressions = dict_gene_expressions[\"mrna_agilent_microarray\"].copy()\n",
    "df_gene_expressions = rename_duplicatged_columns(df_gene_expressions)\n",
    "df_gene_expressions = drop_null4cols(df_gene_expressions)\n",
    "df_gene_expressions = drop_null4raws(df_gene_expressions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246efeb-3fdd-4192-95a3-b1a5ef3bbd0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 臨床データと遺伝子データの結合\n",
    "\n",
    "患者の必要な特徴を含む臨床データと遺伝子データを結合する。\n",
    "\n",
    "## 臨床データ\n",
    "\n",
    "**必要な特徴**\n",
    "\n",
    "目的変数\n",
    "- RFS_OVER_nMONTHS  \n",
    "\n",
    "層別化対象候補\n",
    "- CLAUDIN_SUBTYPE\n",
    "- NPI_CAT\n",
    "- TUMOR_CAT\n",
    "- LYMPH_CAT\n",
    "\n",
    "## 遺伝子データ\n",
    "遺伝子データは全ての特徴量を結合する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f87a9c8c-799d-492b-ad6e-3a0549d91063",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_features = [\n",
    "    \"RFS_STATUS\",\n",
    "    TARGET_NAME,\n",
    "    \"CLAUDIN_SUBTYPE\",\n",
    "    \"NPI_CAT\",\n",
    "    \"TUMOR_CAT\",\n",
    "    \"LYMPH_CAT\",\n",
    "]\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_MB[left_features],\n",
    "    df_gene_expressions,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "functions.make_dir(config.INTERIM_PREPROCESSED_RECURRENCE_DIR)\n",
    "df_gene_expressions.to_pickle(\n",
    "    config.INTERIM_PREPROCESSED_RECURRENCE_DIR + \"/df_gene_expressions.pkl\"\n",
    ")\n",
    "df_merged.to_pickle(config.INTERIM_PREPROCESSED_RECURRENCE_DIR + \"/df_merged.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83436e1-d418-4b14-9c73-606b393cce72",
   "metadata": {},
   "source": [
    "## 再発者の抽出\n",
    "\n",
    "再発者のみを対象とするため、再発者を抽出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ea2a2f0-5551-442a-9516-05d9a9f2d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recurrenced = df_merged[df_merged[\"RFS_STATUS\"] == 1].drop(\"RFS_STATUS\", axis=1)\n",
    "df_recurrenced.shape\n",
    "\n",
    "# save\n",
    "functions.make_dir(config.INTERIM_PREPROCESSED_RECURRENCE_DIR)\n",
    "df_recurrenced.to_pickle(\n",
    "    config.INTERIM_PREPROCESSED_RECURRENCE_DIR + \"/df_recurrenced.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0284746c-8c80-4c32-86b5-34e1d48047b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## データ分割\n",
    "\n",
    "訓練データ、検証データ、テストデータに層化分割する   \n",
    "比率は(train, val, test)=(0.81, 0.09, 0.1)  \n",
    "CVは行わずに通常のholdoutで検証は行う（特徴選択を毎度実施するのが厄介なため）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76e02b5c-90c3-40a6-94d3-efecef50364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ分割のためのクラス\n",
    "# pythonのミュータブルオブジェクトの外部操作を防ぐためにcopy()の使用&private化\n",
    "class SplitDataFrame:\n",
    "    def __init__(self, df):\n",
    "        self.__df = df.copy()\n",
    "        self.__train_size = 0.9\n",
    "\n",
    "        self.__df_train_val = None\n",
    "        self.__df_train = None\n",
    "        self.__df_val = None\n",
    "        self.__df_test = None\n",
    "\n",
    "        self.__X_train_val = None\n",
    "        self.__y_train_val = None\n",
    "        self.__X_train = None\n",
    "        self.__y_train = None\n",
    "        self.__X_val = None\n",
    "        self.__y_val = None\n",
    "        self.__X_test = None\n",
    "        self.__y_test = None\n",
    "\n",
    "    def split_train_val_test(self):\n",
    "        # train & test\n",
    "        self.__df_train_val, self.__df_test = train_test_split(\n",
    "            self.__df,\n",
    "            train_size=self.__train_size,\n",
    "            stratify=self.__df[TARGET_NAME],\n",
    "            random_state=SEED,\n",
    "        )\n",
    "        # train & val\n",
    "        self.__df_train, self.__df_val = train_test_split(\n",
    "            self.__df_train_val,\n",
    "            train_size=self.__train_size,\n",
    "            stratify=self.__df_train_val[TARGET_NAME],\n",
    "            random_state=SEED,\n",
    "        )\n",
    "\n",
    "    def split_X_y(self):\n",
    "        self.__X_train, self.__y_train = (\n",
    "            self.__df_train.drop(TARGET_NAME, axis=1),\n",
    "            self.__df_train[TARGET_NAME],\n",
    "        )\n",
    "        self.__X_val, self.__y_val = (\n",
    "            self.__df_val.drop(TARGET_NAME, axis=1),\n",
    "            self.__df_val[TARGET_NAME],\n",
    "        )\n",
    "        self.__X_train_val, self.__y_train_val = (\n",
    "            self.__df_train_val.drop(TARGET_NAME, axis=1),\n",
    "            self.__df_train_val[TARGET_NAME],\n",
    "        )\n",
    "        self.__X_test, self.__y_test = (\n",
    "            self.__df_test.drop(TARGET_NAME, axis=1),\n",
    "            self.__df_test[TARGET_NAME],\n",
    "        )\n",
    "    \n",
    "    def get_train_val(self):\n",
    "        return self.__train_val.copy()\n",
    "\n",
    "    def get_train(self):\n",
    "        return self.__train.copy()\n",
    "    \n",
    "    def get_val(self):\n",
    "        return self.__val.copy()\n",
    "\n",
    "    def get_test(self):\n",
    "        return self.__test.copy()\n",
    "\n",
    "    def get_train_val_Xy(self):\n",
    "        return self.__X_train_val.copy(), self.__y_train_val.copy()\n",
    "\n",
    "    def get_train_Xy(self):\n",
    "        return self.__X_train.copy(), self.__y_train.copy()\n",
    "\n",
    "    def get_val_Xy(self):\n",
    "        return self.__X_val.copy(), self.__y_val.copy()\n",
    "\n",
    "    def get_test_Xy(self):\n",
    "        return self.__X_test.copy(), self.__y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f949a6d0-33ef-4383-8312-949775980915",
   "metadata": {},
   "source": [
    "# 特徴選択\n",
    "\n",
    "特徴数が多いため、特徴数を削減する\n",
    "\n",
    "**目安**\n",
    "サンプル数が767件であり、8割程度が学習に使用できる(train : val : test = 0.9*0.9 : 0.9*0.1 : 0.1)ため、学習データの1割程度の60個を選択後上限数の目安とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7b707ee-7c2e-48f4-b3af-fe0881c15561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 適用する処理毎にdfをまとめたclass\n",
    "class PreprocessDataFrame:\n",
    "    def __init__(self, df_raw):\n",
    "        self.__raw = df_raw.copy()\n",
    "        self.__preprocessed = None\n",
    "        self.__preprocess_methods = list()\n",
    "\n",
    "    def get_preprocessed_df(self):\n",
    "        return self.__preprocessed.copy()\n",
    "\n",
    "    def get_preprocess_methods(self):\n",
    "        return self.__preprocess_methods.copy()\n",
    "\n",
    "    # feature_selection\n",
    "    def set_vt(self, df):\n",
    "        \"\"\"\n",
    "        分散によるフィルターで特徴を選択したdf\n",
    "        \"\"\"\n",
    "        self.__preprocess_methods.append(\"vt\")\n",
    "        self.__preprocessed = df\n",
    "\n",
    "    def set_mrmr(self, df):\n",
    "        \"\"\"\n",
    "        mrmrで特徴を選択したdf\n",
    "        \"\"\"\n",
    "        self.__preprocess_methods.append(\"mrmr\")\n",
    "        self.__preprocessed = df\n",
    "\n",
    "    # scaling\n",
    "    def set_std(self, df):\n",
    "        \"\"\"\n",
    "        standarization\n",
    "        \"\"\"\n",
    "        self.__preprocess_methods.append(\"std\")\n",
    "        self.__preprocessed = df\n",
    "        # scaling\n",
    "\n",
    "    def set_norm(self, df):\n",
    "        \"\"\"\n",
    "        normalization\n",
    "        \"\"\"\n",
    "        self.__preprocess_methods.append(\"norm\")\n",
    "        self.__preprocessed = df\n",
    "\n",
    "    # sampling\n",
    "    def set_smote(self, df):\n",
    "        \"\"\"\n",
    "        smote\n",
    "        \"\"\"\n",
    "        self.__preprocess_methods.append(\"smote\")\n",
    "        self.__preprocessed = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b9e7b-a113-4df0-860e-d6044331639b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 分割データ毎に前処理を行う関数の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3b06588-8a4f-490e-a67a-2b422e4aae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocessed_df(\n",
    "    list_train: list(),\n",
    "    list_val: list(),\n",
    "    list_train_val: list(),\n",
    "    list_test: list(),\n",
    "    save_file_path: str = \".\",\n",
    "    save_file_name: str = \"sample\",\n",
    "):\n",
    "    \"\"\"\n",
    "    params\n",
    "    list_train: [X_train, y_train]\n",
    "    list_val: [X_val, y_val]\n",
    "    list_train_val: [X_train_val, y_train_val]\n",
    "    list_test: [X_val, y_val]\n",
    "    \"\"\"\n",
    "    functions.make_dir(\"{0}/train\".format(save_file_path))\n",
    "    list_train[0].to_pickle(\n",
    "        \"{0}/train/X_{1}.pkl\".format(save_file_path, save_file_name)\n",
    "    )\n",
    "    list_train[1].to_pickle(\n",
    "        \"{0}/train/y_{1}.pkl\".format(save_file_path, save_file_name)\n",
    "    )\n",
    "    functions.make_dir(\"{0}/val\".format(save_file_path))\n",
    "    list_val[0].to_pickle(\"{0}/val/X_{1}.pkl\".format(save_file_path, save_file_name))\n",
    "    list_val[1].to_pickle(\"{0}/val/y_{1}.pkl\".format(save_file_path, save_file_name))\n",
    "\n",
    "    functions.make_dir(\"{0}/train_val\".format(save_file_path))\n",
    "    list_train_val[0].to_pickle(\n",
    "        \"{0}/train_val/X_{1}.pkl\".format(save_file_path, save_file_name)\n",
    "    )\n",
    "    list_train_val[1].to_pickle(\n",
    "        \"{0}/train_val/y_{1}.pkl\".format(save_file_path, save_file_name)\n",
    "    )\n",
    "    functions.make_dir(\"{0}/test\".format(save_file_path))\n",
    "    list_test[0].to_pickle(\"{0}/test/X_{1}.pkl\".format(save_file_path, save_file_name))\n",
    "    list_test[1].to_pickle(\"{0}/test/y_{1}.pkl\".format(save_file_path, save_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825d22b-f1d1-411d-b40b-ae06fd337321",
   "metadata": {},
   "source": [
    "## scaling関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b37c628-b200-4640-b97e-f27acaad53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化を行う関数\n",
    "def transform_std(X_train: pd.DataFrame(), X_test: pd.DataFrame() = None):\n",
    "    std = StandardScaler()\n",
    "    std.fit(X_train)\n",
    "    X_train_std = pd.DataFrame(\n",
    "        std.transform(X_train), index=X_train.index, columns=X_train.columns\n",
    "    )\n",
    "    if X_test is None:\n",
    "        return X_train_std\n",
    "    X_test_std = pd.DataFrame(\n",
    "        std.transform(X_test), index=X_test.index, columns=X_test.columns\n",
    "    )\n",
    "    return X_train_std, X_test_std\n",
    "\n",
    "\n",
    "# 正規化を行う関数\n",
    "def transform_norm(\n",
    "    X_train: pd.DataFrame(), X_test: pd.DataFrame() = None\n",
    ") -> pd.DataFrame():\n",
    "    mm = MinMaxScaler()\n",
    "    mm.fit(X_train)\n",
    "    X_train_norm = pd.DataFrame(\n",
    "        mm.transform(X_train), index=X_train.index, columns=X_train.columns\n",
    "    )\n",
    "    if X_test is None:\n",
    "        return X_train_norm\n",
    "    X_test_norm = pd.DataFrame(\n",
    "        mm.transform(X_test), index=X_test.index, columns=X_test.columns\n",
    "    )\n",
    "    return X_train_norm, X_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8009324f-ed10-4082-a6af-abf5cc531e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_df(\n",
    "    df: pd.DataFrame(),\n",
    "    feature_selection_method: str = None,\n",
    "    scaling_method: str = None,\n",
    "    sampling_method: str = None,\n",
    "    save_file_path: str = None,\n",
    "    save_file_name: str = None,\n",
    "    is_save: bool = False,\n",
    "):\n",
    "    _df = df.copy()\n",
    "\n",
    "    # データが少なすぎる場合は特徴選択しない\n",
    "    if _df.shape[0] < 100:\n",
    "        # print(\"data size is too small\")\n",
    "        return\n",
    "\n",
    "    # データ分割\n",
    "    sp = SplitDataFrame(_df)\n",
    "    sp.split_train_val_test()\n",
    "    sp.split_X_y()\n",
    "\n",
    "    X_train, y_train = sp.get_train_Xy()\n",
    "    X_val, y_val = sp.get_val_Xy()\n",
    "    X_train_val, y_train_val = sp.get_train_val_Xy()\n",
    "    X_test, y_test = sp.get_test_Xy()\n",
    "\n",
    "    # class初期化\n",
    "    pd_train = PreprocessDataFrame(X_train)\n",
    "    pd_val = PreprocessDataFrame(X_val)\n",
    "    pd_train_val = PreprocessDataFrame(X_train_val)\n",
    "    pd_test = PreprocessDataFrame(X_test)\n",
    "\n",
    "    # feature selection\n",
    "    if feature_selection_method == \"none\":\n",
    "        pass\n",
    "    elif feature_selection_method == \"vt\":\n",
    "        # 分散値上位の特徴を抽出\n",
    "        features = (\n",
    "            X_train.var().sort_values().tail(X_train.shape[0] // 10).index\n",
    "        )  # 学習データの1/10サイズ\n",
    "        pd_train.set_vt(X_train[features])\n",
    "        pd_val.set_vt(X_val[features])\n",
    "\n",
    "        features = (\n",
    "            X_train_val.var()\n",
    "            .sort_values()\n",
    "            .tail(X_train_val.shape[0] // 10)\n",
    "            .index  # 学習データの1/10サイズ\n",
    "        )\n",
    "        pd_train_val.set_vt(X_train_val[features])\n",
    "        pd_test.set_vt(X_test[features])\n",
    "    elif feature_selection_method == \"mrmr\":\n",
    "        features = mrmr.mrmr_classif(\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            K=X_train.shape[0] // 10,  # 学習データの1/10サイズ\n",
    "            show_progress=False,\n",
    "        )\n",
    "        pd_train.set_mrmr(X_train[features])\n",
    "        pd_val.set_mrmr(X_val[features])\n",
    "\n",
    "        features = mrmr.mrmr_classif(\n",
    "            X=X_train_val,\n",
    "            y=y_train_val,\n",
    "            K=X_train_val.shape[0] // 10,  # 学習データの1/10サイズ\n",
    "            show_progress=False,\n",
    "        )\n",
    "        pd_train_val.set_mrmr(X_train_val[features])\n",
    "        pd_test.set_mrmr(X_test[features])\n",
    "    else:\n",
    "        print(\"undefined feature_selection_method\")\n",
    "        return\n",
    "\n",
    "    # scaling\n",
    "    if scaling_method == \"none\":\n",
    "        pass\n",
    "    elif scaling_method == \"std\":\n",
    "        X_train, X_val = transform_std(\n",
    "            pd_train.get_preprocessed_df(), pd_val.get_preprocessed_df()\n",
    "        )\n",
    "        X_train_val, X_test = transform_std(\n",
    "            pd_train_val.get_preprocessed_df(), pd_test.get_preprocessed_df()\n",
    "        )\n",
    "        pd_train.set_std(X_train)\n",
    "        pd_val.set_std(X_val)\n",
    "        pd_train_val.set_std(X_train_val)\n",
    "        pd_test.set_std(X_test)\n",
    "    elif scaling_method == \"norm\":\n",
    "        X_train, X_val = transform_norm(\n",
    "            pd_train.get_preprocessed_df(), pd_val.get_preprocessed_df()\n",
    "        )\n",
    "        X_train_val, X_test = transform_norm(\n",
    "            pd_train_val.get_preprocessed_df(), pd_test.get_preprocessed_df()\n",
    "        )\n",
    "        pd_train.set_norm(X_train)\n",
    "        pd_val.set_std(X_val)\n",
    "        pd_train_val.set_std(X_train_val)\n",
    "        pd_test.set_std(X_test)\n",
    "    else:\n",
    "        print(\"undefined scaling_method\")\n",
    "        return\n",
    "\n",
    "    # sampling\n",
    "    if sampling_method == \"none\":\n",
    "        pass\n",
    "    elif sampling_method == \"smote\":\n",
    "        smote = SMOTE(sampling_strategy=\"minority\", random_state=SEED)\n",
    "        X_train, y_train = smote.fit_resample(pd_train.get_preprocessed_df(), y_train)\n",
    "        smote = SMOTE(sampling_strategy=\"minority\", random_state=SEED)\n",
    "        X_train_val, y_train_val = smote.fit_resample(\n",
    "            pd_train_val.get_preprocessed_df(), y_train_val\n",
    "        )\n",
    "        pd_train.set_smote(X_train)\n",
    "        pd_train_val.set_smote(X_train_val)\n",
    "    else:\n",
    "        print(\"undefined sampling_method\")\n",
    "        return\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"applied preprocess (train): \", pd_train.get_preprocess_methods())\n",
    "    print(\"shape (train): \", pd_train.get_preprocessed_df().shape, y_train.shape)\n",
    "    print(\"applied preprocess (val): \", pd_val.get_preprocess_methods())\n",
    "    print(\"shape (val): \", pd_val.get_preprocessed_df().shape, y_val.shape)\n",
    "    print(\"applied preprocess (train_val): \", pd_train_val.get_preprocess_methods())\n",
    "    print(\n",
    "        \"shape (train_val): \",\n",
    "        pd_train_val.get_preprocessed_df().shape,\n",
    "        y_train_val.shape,\n",
    "    )\n",
    "    print(\"applied preprocess (test): \", pd_test.get_preprocess_methods())\n",
    "    print(\"shape (test): \", pd_test.get_preprocessed_df().shape, y_test.shape)\n",
    "    \"\"\"\n",
    "    # 保存\n",
    "    if is_save:\n",
    "        save_preprocessed_df(\n",
    "            list_train=[pd_train.get_preprocessed_df(), y_train],\n",
    "            list_val=[pd_val.get_preprocessed_df(), y_val],\n",
    "            list_train_val=[pd_train_val.get_preprocessed_df(), y_train_val],\n",
    "            list_test=[pd_test.get_preprocessed_df(), y_test],\n",
    "            save_file_path=save_file_path,\n",
    "            save_file_name=save_file_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02fd87f4-1d1f-48aa-b328-079b0dfdcaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [1:06:35, 499.50s/it]\n"
     ]
    }
   ],
   "source": [
    "is_save = True\n",
    "\n",
    "# サブグループ削除（一時的に）\n",
    "subgroup_columns = [\n",
    "    \"CLAUDIN_SUBTYPE\",\n",
    "    \"NPI_CAT\",\n",
    "    \"TUMOR_CAT\",\n",
    "    \"LYMPH_CAT\",\n",
    "]\n",
    "\n",
    "drop_columns = [\n",
    "    \"CLAUDIN_SUBTYPE\",\n",
    "    \"NPI_CAT\",\n",
    "    \"TUMOR_CAT\",\n",
    "    \"LYMPH_CAT\",\n",
    "]\n",
    "\n",
    "feature_selection_methods = [\"vt\", \"mrmr\"]\n",
    "\n",
    "scaling_methods = [\"std\", \"norm\"]\n",
    "\n",
    "sampling_methods = [\"none\", \"smote\"]\n",
    "\n",
    "for feature_selection_method, scaling_method, sampling_method in tqdm(\n",
    "    itertools.product(feature_selection_methods, scaling_methods, sampling_methods)\n",
    "):\n",
    "    preprocess_order = \"{0}_{1}_{2}\".format(\n",
    "        feature_selection_method, scaling_method, sampling_method\n",
    "    )\n",
    "    for subgroup_column in subgroup_columns:  # 各サブグループへの適用\n",
    "        for subgroup in df_recurrenced[subgroup_column].unique():  # サブグループ毎への適用\n",
    "            df = df_recurrenced[df_recurrenced[subgroup_column] == subgroup].drop(\n",
    "                drop_columns, axis=1\n",
    "            )\n",
    "            output_file_path = \"./{0}/{1}/{2}\".format(\n",
    "                config.INTERIM_PREPROCESSED_RECURRENCE_DIR,\n",
    "                subgroup_column,\n",
    "                preprocess_order,\n",
    "            )\n",
    "            functions.make_dir(output_file_path)\n",
    "            preprocess_df(\n",
    "                df,\n",
    "                feature_selection_method=feature_selection_method,\n",
    "                scaling_method=scaling_method,\n",
    "                sampling_method=sampling_method,\n",
    "                save_file_path=output_file_path,\n",
    "                save_file_name=subgroup,\n",
    "                is_save=is_save,\n",
    "            )\n",
    "            del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c5c7c0-c9df-405f-b84d-acf8af754597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
